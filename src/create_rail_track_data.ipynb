{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a6956cf",
   "metadata": {},
   "source": [
    "### This program combines the mos_archi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87583bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76d685e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(timestamp):\n",
    "    try:\n",
    "        return datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "    except ValueError:\n",
    "        return datetime.strptime(timestamp, \"%Y-%m-%d\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da993907",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmos = pd.read_csv(r'/home/daniel/projects/rails/data/mos_archive_data_hourly_data_for_all_rail_stations_sep2019_aug2023.csv', sep = ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b4ea64b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3969240, 33)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data for  2021-11-04 12:00:00' are not correct in Mos Archive, so that data is removed \n",
    "df = dfmos[~(dfmos['analysis_date'] ==  '2021-11-04 12:00:00')]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c084feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hourly_values(df, param):\n",
    "    h_param = f'{param}1h'\n",
    "    df_hourly_param = pd.DataFrame(columns=['lat', 'lon', 'analysis_date', 'forecast_period', h_param])\n",
    "    unique_latlon_pairs = df[['lat', 'lon']].drop_duplicates()\n",
    "\n",
    "    def process_row(row_tuple):\n",
    "        index, row = row_tuple\n",
    "        lat, lon = row['lat'], row['lon']\n",
    "        filtered_df = df[(df['lat'] == lat) & (df['lon'] == lon)]\n",
    "        analysis_dates = filtered_df['analysis_date'].unique()\n",
    "        result_rows = []\n",
    "        for ad in analysis_dates:\n",
    "            ad_filtered_df = filtered_df[filtered_df['analysis_date'] == ad]\n",
    "            period = 1\n",
    "            while period <= 240:  # Adjust the condition based on your specific requirement\n",
    "                #print(period)\n",
    "                if period < 90:\n",
    "                    increment = 1\n",
    "                elif period < 144:\n",
    "                    increment = 3\n",
    "                else:\n",
    "                    increment = 6\n",
    "                period_filtered_df = ad_filtered_df[ad_filtered_df['forecast_period'] == period]\n",
    "                param_values = period_filtered_df[param].values\n",
    "                if len(param_values) > 0:\n",
    "                    param_value = param_values[0]\n",
    "                    if period == 1:\n",
    "                        param_value = param_value/3600 # convert to Watts (Joules/sec)\n",
    "                        result_rows.append({'lat': lat, 'lon': lon, 'analysis_date': ad, 'forecast_period': period, h_param: param_value})\n",
    "                    else:\n",
    "                        prev_period = period - increment\n",
    "                        prev_period_filtered_df = ad_filtered_df[ad_filtered_df['forecast_period'] == prev_period]\n",
    "                        prev_param_values = prev_period_filtered_df[param].values\n",
    "                        if len(prev_param_values) > 0:\n",
    "                            prev_param_value = prev_param_values[0]\n",
    "                            param_difference = param_value - prev_param_value\n",
    "                            param_value = param_difference / (increment * 3600)\n",
    "                            result_rows.append({'lat': lat, 'lon': lon, 'analysis_date': ad, 'forecast_period': period, h_param: param_value})\n",
    "                        else: # prev_parameter has no value\n",
    "                            print(param,lat, lon, period, ad)\n",
    "                else: # parameter has no value\n",
    "                    print(param,lat, lon, period, ad)\n",
    "                period += increment  # Increment the period using the calculated increment\n",
    "        return result_rows\n",
    "    result_rows = [row for rows in map(process_row, unique_latlon_pairs.iterrows()) for row in rows]\n",
    "    df_hourly_param = pd.DataFrame(result_rows)\n",
    "\n",
    "    return df_hourly_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54cc99ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR\n",
      "elapsed_time:  2273.999979734421\n",
      "STR\n",
      "elapsed_time:  2224.440554380417\n",
      "SLHF\n",
      "elapsed_time:  2185.547898054123\n",
      "SSHF\n",
      "elapsed_time:  2210.199623823166\n"
     ]
    }
   ],
   "source": [
    "# creating the hourly values for SRR','STR', 'SLHF', 'SSHF'\n",
    "import time\n",
    "hourly_parameters = ['SRR','STR', 'SLHF', 'SSHF']\n",
    "for param in hourly_parameters:\n",
    "    print(param)\n",
    "    start_time = time.time()\n",
    "    df_hourly_param = calculate_hourly_values(df, param)\n",
    "    df = df.merge(df_hourly_param, on=['lat', 'lon', 'analysis_date', 'forecast_period'])\n",
    "    end_time = time.time()\n",
    "    print(f'elapsed_time: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7cdfed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3969240, 37)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "870d41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/daniel/projects/rails/data/mos_archive_data_corrected_hourly_data_for_all_rail_stations_sep2019_aug2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ca1742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rail temperature data from Väylävirasto\n",
    "df = pd.read_csv(r'/home/daniel/projects/rails/data/RailTemperatures_with_stations_sep2019_aug2023.csv', encoding = 'Latin-1',sep = ',')\n",
    "\n",
    "df['lat'] = round(df['lat'],3)\n",
    "df['lon'] = round(df['lon'],3)\n",
    "\n",
    "df = df[~((df['station_id'] == 31) &  (pd.to_datetime(df['Timestamp']) >= '2022-09-01 00:00:00'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92f3bd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>station_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TAir</th>\n",
       "      <th>TRail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hammaslahti</td>\n",
       "      <td>10</td>\n",
       "      <td>62.398</td>\n",
       "      <td>30.027</td>\n",
       "      <td>6922164</td>\n",
       "      <td>656442</td>\n",
       "      <td>2019-09-17 12:00:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hammaslahti</td>\n",
       "      <td>10</td>\n",
       "      <td>62.398</td>\n",
       "      <td>30.027</td>\n",
       "      <td>6922164</td>\n",
       "      <td>656442</td>\n",
       "      <td>2019-09-17 13:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hammaslahti</td>\n",
       "      <td>10</td>\n",
       "      <td>62.398</td>\n",
       "      <td>30.027</td>\n",
       "      <td>6922164</td>\n",
       "      <td>656442</td>\n",
       "      <td>2019-09-17 14:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hammaslahti</td>\n",
       "      <td>10</td>\n",
       "      <td>62.398</td>\n",
       "      <td>30.027</td>\n",
       "      <td>6922164</td>\n",
       "      <td>656442</td>\n",
       "      <td>2019-09-17 14:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hammaslahti</td>\n",
       "      <td>10</td>\n",
       "      <td>62.398</td>\n",
       "      <td>30.027</td>\n",
       "      <td>6922164</td>\n",
       "      <td>656442</td>\n",
       "      <td>2019-09-17 16:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336897</th>\n",
       "      <td>Tupos</td>\n",
       "      <td>80</td>\n",
       "      <td>64.879</td>\n",
       "      <td>25.503</td>\n",
       "      <td>7195843</td>\n",
       "      <td>429111</td>\n",
       "      <td>2023-06-01 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336898</th>\n",
       "      <td>Tupos</td>\n",
       "      <td>80</td>\n",
       "      <td>64.879</td>\n",
       "      <td>25.503</td>\n",
       "      <td>7195843</td>\n",
       "      <td>429111</td>\n",
       "      <td>2023-06-01 18:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336899</th>\n",
       "      <td>Tupos</td>\n",
       "      <td>80</td>\n",
       "      <td>64.879</td>\n",
       "      <td>25.503</td>\n",
       "      <td>7195843</td>\n",
       "      <td>429111</td>\n",
       "      <td>2023-06-01 13:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336900</th>\n",
       "      <td>Tupos</td>\n",
       "      <td>80</td>\n",
       "      <td>64.879</td>\n",
       "      <td>25.503</td>\n",
       "      <td>7195843</td>\n",
       "      <td>429111</td>\n",
       "      <td>2023-06-01 10:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336901</th>\n",
       "      <td>Tupos</td>\n",
       "      <td>80</td>\n",
       "      <td>64.879</td>\n",
       "      <td>25.503</td>\n",
       "      <td>7195843</td>\n",
       "      <td>429111</td>\n",
       "      <td>2023-06-01 09:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331194 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            station  station_id     lat     lon        X       Y  \\\n",
       "0       Hammaslahti          10  62.398  30.027  6922164  656442   \n",
       "1       Hammaslahti          10  62.398  30.027  6922164  656442   \n",
       "2       Hammaslahti          10  62.398  30.027  6922164  656442   \n",
       "3       Hammaslahti          10  62.398  30.027  6922164  656442   \n",
       "4       Hammaslahti          10  62.398  30.027  6922164  656442   \n",
       "...             ...         ...     ...     ...      ...     ...   \n",
       "336897        Tupos          80  64.879  25.503  7195843  429111   \n",
       "336898        Tupos          80  64.879  25.503  7195843  429111   \n",
       "336899        Tupos          80  64.879  25.503  7195843  429111   \n",
       "336900        Tupos          80  64.879  25.503  7195843  429111   \n",
       "336901        Tupos          80  64.879  25.503  7195843  429111   \n",
       "\n",
       "                  Timestamp  TAir  TRail  \n",
       "0       2019-09-17 12:00:00  12.0   14.0  \n",
       "1       2019-09-17 13:00:00  11.0   14.0  \n",
       "2       2019-09-17 14:00:00  11.0   16.0  \n",
       "3       2019-09-17 14:00:00  11.0   15.0  \n",
       "4       2019-09-17 16:00:00  11.0   15.0  \n",
       "...                     ...   ...    ...  \n",
       "336897  2023-06-01 23:00:00   1.0    2.0  \n",
       "336898  2023-06-01 18:00:00   9.0   14.0  \n",
       "336899  2023-06-01 13:00:00   7.0   16.0  \n",
       "336900  2023-06-01 10:00:00   7.0   17.0  \n",
       "336901  2023-06-01 09:00:00   6.0   12.0  \n",
       "\n",
       "[331194 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a208457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast data from MOS archive\n",
    "dfmos = pd.read_csv(r'/home/daniel/projects/rails/data/mos_archive_data_corrected_hourly_data_for_all_rail_stations_sep2019_aug2023.csv', sep = ',')\n",
    "\n",
    "# rounding the latitide and longitude to 3 digits\n",
    "dfmos.loc[:,'lat'] = round(dfmos['lat'],3)\n",
    "dfmos.loc[:,'lon'] = round(dfmos['lon'],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c72ac216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating  the wind speed (WS) from the U10 and V10 components\n",
    "dfmos.loc[:, 'WS'] = np.sqrt(np.square(dfmos['U10']) + np.square(dfmos['V10']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dcd9b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station_id', 'analysis_time', 'forecast_time', 'forecast_period',\n",
       "       'analysis_date', 'MSL', 'T2', 'D2', 'U10', 'V10', 'LCC', 'MCC', 'SKT',\n",
       "       'MX2T', 'MN2T', 'T_925', 'T2_ENSMEAN_MA1', 'SRR', 'STR', 'SLHF', 'SSHF',\n",
       "       'cosmonth', 'sinmonth', 'coshour', 'sinhour', 'lat', 'lon', 'cosDoY',\n",
       "       'sinDoY', 'hourly_STR', 'hourly_SLHF', 'hourly_SSHF', 'hourly_SRR',\n",
       "       'SRR1h', 'STR1h', 'SLHF1h', 'SSHF1h', 'WS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34ce4a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8096/290663528.py:2: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  dfmos.loc[:, 'forecast_time'] = dfmos.loc[:,'forecast_time'].apply(convert_to_datetime)\n",
      "/tmp/ipykernel_8096/290663528.py:4: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  dfmos.loc[:, 'forecast_time'] = dfmos.loc[:,'forecast_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n"
     ]
    }
   ],
   "source": [
    "# converting the dfmos forecast time in  yyyy-mm-dd format to yyyy-mm-dd HH:MM:SS format\n",
    "dfmos.loc[:, 'forecast_time'] = dfmos.loc[:,'forecast_time'].apply(convert_to_datetime)\n",
    "# Convert the datetime objects back to string in the desired format\n",
    "dfmos.loc[:, 'forecast_time'] = dfmos.loc[:,'forecast_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83c20fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['analysis_time', 'forecast_time', 'forecast_period',\n",
    "       'analysis_date', 'MSL', 'T2', 'T_925', 'D2', 'WS', 'LCC', 'MCC', 'SKT',\n",
    "       'cosmonth', 'sinmonth', 'coshour', 'sinhour','cosDoY', 'sinDoY', 'lat', 'lon',\n",
    "       'SRR1h', 'STR1h','SLHF1h','SSHF1h' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cc90560",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmos = dfmos[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "508128e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  combining the rail temperature data from Väylävirasto and the ECMWF forecast data from MOS archive\n",
    "dfmosrail= dfmos.merge(df,left_on = ['forecast_time','lat', 'lon'], right_on = ['Timestamp','lat', 'lon'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fc52272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined  data \n",
    "dfmosrail.to_csv('/home/daniel/projects/rails/data/rail_temperatures_mos_data_sep2019_aug2023_corrected_radiation_params.csv', sep = ',', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
